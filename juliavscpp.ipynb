{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Julia as Fast as C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Achieving C++ Performance in Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"vid/vortex00.gif\" alt=\"Vid here\" width=\"250px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module CxxVortexTest.\n"
     ]
    }
   ],
   "source": [
    "#=\n",
    "    This cell loads auxiliary benchmarking functions available \n",
    "    here: https://github.com/EdoAlvarezR/post-juliavscpp\n",
    "=#\n",
    "using LinearAlgebra\n",
    "\n",
    "# Load C++ code wrapped as module CxxVortexTest\n",
    "include(\"code/vortextest.jl\")\n",
    "\n",
    "# Load benchmarking tools\n",
    "include(\"code/benchmarking.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The myth says that Julia can achieve the [same computing performance](https://julialang.org/benchmarks/) than any other compiled language like C++ and FORTRAN. After coding in Julia for the past two years I have definitely fell in love with its pythonic syntax, multiple dispatch, and its MATLAB-like handiness in linear algebra, while being able to use compilation features like explicit type declaration for bug-preventive programming. In summary, Julia's phylosophy brings all the flexibility of an intepreted language, meanwhile its Just-In-Time (JIT) compilation modus operandi makes it a defacto compiled language.\n",
    "\n",
    "Julia's high level syntax makes the language easygoing for programmers from any background or experience level, however, achieving high performance is sort of an art. In this post I summarize some of the things I've learned while crafting my Julia codes for high-performance computing. I will attempt to show the process of code optimization through a real-world computing application from aerodynamics: the [vortex particle method](https://scholarsarchive.byu.edu/facpub/2116/)$^{[1,\\,2]}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [vortex particle method](https://scholarsarchive.byu.edu/facpub/2116/) we are interested in calculating the velocity $\\mathbf{u}$ and velocity Jacobian $\\mathbf{J}$ that a field of $N$ vortex particles induces at an arbitrary position $\\mathbf{x}$. This is calculated as\n",
    "\n",
    "\\begin{align}\n",
    "    \\bullet \\quad &\n",
    "\t\t{\\bf u}\\left( {\\bf x} \\right) = \\sum\\limits_p^N g_\\sigma\\left( {\\bf x}-{\\bf x}_p \\right)\n",
    "\t\t\t\t\t\t{\\bf K}\\left( {\\bf x}-{\\bf x}_p \\right)   \\times\n",
    "\t\t\t            \\boldsymbol\\Gamma_p \n",
    "    \\\\\n",
    "    \\bullet \\quad &\n",
    "        \\frac{\\partial {\\bf u}}{\\partial x_j}\\left( {\\bf x} \\right) \n",
    "        = \\sum\\limits_p^N \\left[\n",
    "            \\left(\n",
    "                \\frac{1}{\\sigma }\n",
    "                 \\frac{\\Delta x_j}{\\Vert \\Delta \\mathbf{x} \\Vert}\n",
    "                 \\frac{\\partial g}{\\partial r}\n",
    "                 \\left( \n",
    "                             \\frac{\\Vert \\Delta\\mathbf{x} \\Vert}{\\sigma} \n",
    "                 \\right) -\n",
    "                 3 g_\\sigma\\left( \\Delta{\\bf x} \\right) \n",
    "                 \\frac{\\Delta x_j}{\\Vert \\Delta\\mathbf{x} \\Vert^2} \n",
    "            \\right)\n",
    "            {\\bf K}\\left( \\Delta\\mathbf{x} \\right)  \\times \\boldsymbol\\Gamma_p -\n",
    "            \\frac{g_\\sigma\\left( \\Delta{\\bf x} \\right) }{4\\pi \\Vert \\Delta{\\bf x} \\Vert^3}\n",
    "            \\delta_{ij} \\times \\boldsymbol\\Gamma_p\n",
    "        \\right]\n",
    ",\\end{align}\n",
    "\n",
    "with ${\\bf K}$ the singular Newtonian kernel ${\\bf K}\\left( {\\bf x}\\right)=-\\frac{{\\bf x}}{4\\pi \\Vert{\\bf x}\\Vert^3}$, $g_\\sigma$ a regularizing function of smoothing radius $\\sigma$, and $\\mathbf{x}_p$ and $\\boldsymbol{\\Gamma}_p$ the position and vectorial strength of the $p$-th particle, respectively. Furthermore, the governing equations of the method require evaluating the velocity $\\mathbf{u}$ and Jacobian $\\mathbf{J}$ that the collection of particles induces on itself, leading to the ancient [$N$-body problem](https://en.wikipedia.org/wiki/N-body_problem) of computational complexity $\\mathcal{O}(N^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing Winckelmans' regularizing kernel$^{[1]}$ \n",
    "\\begin{align}\n",
    "    \\bullet \\quad &\n",
    "        g(r) = r^3 \\frac{r^2 + 5/2}{\\left( r^2 + 1 \\right)^{5/2}}\n",
    "    \\\\\n",
    "    \\bullet \\quad &\n",
    "        \\frac{\\partial g}{\\partial r} (r) = \\frac{15}{2} \n",
    "            \\frac{r^2}{\\left( r^2 + 1 \\right)^{7/2}}\n",
    ",\\end{align}\n",
    "the above equations are implemented in C++ as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "// Particle-to-particle interactions\n",
    "void P2P(Particle * P, const int numParticles) {\n",
    "\n",
    "  real_t r, ros, aux, g_sgm, dgdr;\n",
    "  vec3 dX;\n",
    "\n",
    "  for (int i=0; i<numParticles; i++) {\n",
    "    for (int j=0; j<numParticles; j++) {\n",
    "\n",
    "      dX[0] = P[i].X[0] - P[j].X[0];\n",
    "      dX[1] = P[i].X[1] - P[j].X[1];\n",
    "      dX[2] = P[i].X[2] - P[j].X[2];\n",
    "      r = sqrt(dX[0]*dX[0] + dX[1]*dX[1] + dX[2]*dX[2]);\n",
    "\n",
    "      if (r!=0){\n",
    "          ros = r/P[j].sigma;\n",
    "\n",
    "          // Evaluate g_σ and ∂gσ∂r\n",
    "          aux = pow(ros*ros + 1.0, 2.5);\n",
    "          g_sgm = ros*ros*ros * (ros*ros + 2.5) / aux;\n",
    "          dgdr = 7.5 * ros*ros / ( aux * (ros*ros + 1.0) );\n",
    "\n",
    "          // u(x) = ∑g_σ(x−xp) K(x−xp) × Γp\n",
    "          aux = (- const4 / (r*r*r)) * g_sgm;\n",
    "          P[i].U[0] += ( dX[1]*P[j].Gamma[2] - dX[2]*P[j].Gamma[1] ) * aux;\n",
    "          P[i].U[1] += ( dX[2]*P[j].Gamma[0] - dX[0]*P[j].Gamma[2] ) * aux;\n",
    "          P[i].U[2] += ( dX[0]*P[j].Gamma[1] - dX[1]*P[j].Gamma[0] ) * aux;\n",
    "\n",
    "          // ∂u∂xj(x) = ∑[ ∂gσ∂xj(x−xp) * K(x−xp)×Γp + gσ(x−xp) * ∂K∂xj(x−xp)×Γp ]\n",
    "          aux = (- const4 / (r*r*r)) * (dgdr/(P[j].sigma*r) - 3.0*g_sgm/(r*r));\n",
    "          for (int k=0; k<3; k++){\n",
    "            P[i].J[3*k + 0] += ( dX[1]*P[j].Gamma[2] - dX[2]*P[j].Gamma[1] )* aux*dX[k];\n",
    "            P[i].J[3*k + 1] += ( dX[2]*P[j].Gamma[0] - dX[0]*P[j].Gamma[2] )* aux*dX[k];\n",
    "            P[i].J[3*k + 2] += ( dX[0]*P[j].Gamma[1] - dX[1]*P[j].Gamma[0] )* aux*dX[k];\n",
    "          }\n",
    "\n",
    "          // Adds the Kronecker delta term\n",
    "          aux = - const4 * g_sgm / (r*r*r);\n",
    "          // k=1\n",
    "          P[i].J[3*0 + 1] -= aux * P[j].Gamma[2];\n",
    "          P[i].J[3*0 + 2] += aux * P[j].Gamma[1];\n",
    "          // k=2\n",
    "          P[i].J[3*1 + 0] += aux * P[j].Gamma[2];\n",
    "          P[i].J[3*1 + 2] -= aux * P[j].Gamma[0];\n",
    "          // k=3\n",
    "          P[i].J[3*2 + 0] -= aux * P[j].Gamma[1];\n",
    "          P[i].J[3*2 + 1] += aux * P[j].Gamma[0];\n",
    "      }\n",
    "\n",
    "    }\n",
    "  }\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a simulation of a 6x6x6 box of particles with vorticity initially concentrated at its center, diffusing as the simulation progresses due to viscous effects:\n",
    "\n",
    "<img src=\"vid/vortex00.gif\" alt=\"Vid here\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## C++ Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here I have [coded a benchmark](https://github.com/EdoAlvarezR/post-juliavscpp) of the C++ code shown above, evaluating `P2P` on a box of 6x6x6 particles, and made it callable in this notebook through the [CxxWrap](https://github.com/JuliaInterop/CxxWrap.jl) Julia package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples:\t1000\n",
      "min time:\t13.3236 ms\n",
      "ave time:\t14.6934 ms\n",
      "max time:\t24.6212 ms\n"
     ]
    }
   ],
   "source": [
    "ntests = 1000               # Tests to run\n",
    "n = 6                       # Particles per edge\n",
    "lambda = 1.5                # Core overlap\n",
    "verbose = true\n",
    "\n",
    "# Run benchmark\n",
    "cpptime = CxxVortexTest.benchmarkP2P_wrap(ntests, n, Float32(lambda), verbose)\n",
    "\n",
    "# Store benchmark result\n",
    "benchtime[\"C++\"] = cpptime;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "P2P kernel Ran in my Dell Latitude 5580 laptop (Intel® Core™ i7-7820HQ CPU @ 2.90GHz × 8 ) in only one process, we see that **the C++ kernel, best-case scenario, is evaluated in ~13 ms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Julia Baseline: Pythonic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Tempted by the Python syntax available in Julia, our first inclination is to make the code as general, simple, and easy to understand as possible. Here is the most general implementation where no types are specified:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P2P_pythonic"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a particle struct made up of ambiguous (unspecified) types\n",
    "\"\"\"\n",
    "struct ParticleAmbiguous\n",
    "\n",
    "    # User inputs\n",
    "    X                               # Position\n",
    "    Gamma                           # Vectorial circulation\n",
    "    sigma                           # Smoothing radius\n",
    "\n",
    "    # Properties\n",
    "    U                               # Velocity at particle\n",
    "    J                               # Jacobian at particle J[i,j]=dUi/dxj\n",
    "\n",
    "    ParticleAmbiguous(X, Gamma, sigma; U=zeros(3), J=zeros(3,3)\n",
    "                      ) = new(X, Gamma, sigma, U, J )\n",
    "end\n",
    "\n",
    "# Empty initializer\n",
    "Base.zero(::Type{<:ParticleAmbiguous}) = ParticleAmbiguous(zeros(3), zeros(3), 0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Winckelmans regularizing kernel\n",
    "g_wnk(r) = r^3 * (r^2 + 2.5) / (r^2 + 1)^2.5\n",
    "dgdr_wnk(r) = 7.5 * r^2 / (r^2 + 1)^3.5\n",
    "\n",
    "const const4 = 1/(4*pi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Pythonic programming approach\n",
    "\"\"\"\n",
    "function P2P_pythonic(particles, g, dgdr)\n",
    "\n",
    "    for Pi in particles \n",
    "        for Pj in particles    \n",
    "\n",
    "            dX = Pi.X - Pj.X\n",
    "            r = norm(dX)\n",
    "\n",
    "            if r != 0\n",
    "\n",
    "                # g_σ and ∂gσ∂r\n",
    "                gsgm = g(r / Pj.sigma)\n",
    "                dgsgmdr = dgdr(r / Pj.sigma)\n",
    "\n",
    "                # K × Γp\n",
    "                crss = cross(-const4 * (dX/r^3), Pj.Gamma) \n",
    "\n",
    "                # U = ∑g_σ(x-xp) * K(x-xp) × Γp\n",
    "                Pi.U[:] += gsgm * crss\n",
    "\n",
    "                # ∂u∂xj(x) = ∑[ ∂gσ∂xj(x−xp) * K(x−xp)×Γp + gσ(x−xp) * ∂K∂xj(x−xp)×Γp ]\n",
    "                for j in 1:3\n",
    "                    Pi.J[:, j] += ( dX[j] / (Pj.sigma*r) * (dgsgmdr*crss) -\n",
    "                                      gsgm * (3*dX[j]/r^2) * crss -\n",
    "                                      gsgm * (const4/r^3) * cross([i==j for i in 1:3], Pj.Gamma) )\n",
    "                end\n",
    "                \n",
    "            end\n",
    "\n",
    "        end\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C++                  is 15.10 times faster than         P2P_pythonic (13.324ms vs 201.173ms)\n",
      "\n",
      "BenchmarkTools.Trial: \n",
      "  memory estimate:  217.57 MiB\n",
      "  allocs estimate:  4087152\n",
      "  --------------\n",
      "  minimum time:     201.173 ms (6.32% GC)\n",
      "  median time:      203.219 ms (6.28% GC)\n",
      "  mean time:        213.188 ms (9.89% GC)\n",
      "  maximum time:     251.125 ms (21.36% GC)\n",
      "  --------------\n",
      "  samples:          5\n",
      "  evals/sample:     1\n"
     ]
    }
   ],
   "source": [
    "# Create a 6x6x6 box of ambiguous particles\n",
    "particles_amb = generate_particles(ParticleAmbiguous, n, lambda)\n",
    "\n",
    "args = (particles_amb, g_wnk, dgdr_wnk)\n",
    "compare(P2P_pythonic, \"C++\", args; reverse=false)\n",
    "\n",
    "@benchmark P2P_pythonic(args...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we see that in our pythonic attempt we've got code that is **pretty neat and concise, but ~15x slower than the C++ implementation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fix #1: Allways work with concrete types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The problem with the pythonic approach is that variable types are never declared, and **without foreknowledge of the types to be handled, Julia can't optimize the function during compilation**. In order to help us catch ambiguous (abstract) types in our code, the Julia `Base` package provides the macro `@code_warntype`, which prints the lowered and type-inferred AST used during compilation highlighting any abstract type encountered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The output is pretty of lengthy, so here I have copied and pasted only a snippet:\n",
    "\n",
    "```julia\n",
    "@code_warntype P2P_pythonic(args...)\n",
    "\n",
    "Body::Nothing\n",
    "│╻╷╷  iterate34 1 ── %1   = (Base.arraylen)(particles)::Int64\n",
    "││╻╷   iterate   │    %2   = (Base.sle_int)(0, %1)::Bool\n",
    "│││╻    <   │    %3   = (Base.bitcast)(UInt64, %1)::UInt64\n",
    "││││╻    <   │    %4   = (Base.ult_int)(0x0000000000000000, %3)::Bool\n",
    "││││╻    &   │    %5   = (Base.and_int)(%2, %4)::Bool\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "│       11 ┄ %33  = φ (#10 => %28, #34 => %149)::ParticleAmbiguous\n",
    "│       │    %34  = φ (#10 => %29, #34 => %150)::Int64\n",
    "│╻    getproperty37 │    %35  = (Base.getfield)(%16, :X)::Any\n",
    "││      │    %36  = (Base.getfield)(%33, :X)::Any\n",
    "│       │    %37  = (%35 - %36)::Any\n",
    "│    38 │    %38  = (Main.norm)(%37)::Any\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Understanding this lowered AST syntax is sort of an art, but you'll soon learn that `@code_warntype` is your best friend when optimizing code. As we scroll down the AST we see that code encounters types `Any` in the properties of our `ParticleAmbiguous` type, which immediately should raise a red flag to us (`Any` is an abstract type). In fact, when running `@code_warntype` the output automatically highlights those `::Any` asserts in red.\n",
    "\n",
    "We can take care of those abstract types by defining the properties of the struct parametrically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a particle struct with property types \n",
    "explicitely/parametrically defined.\n",
    "\"\"\"\n",
    "struct Particle{T}\n",
    "\n",
    "  # User inputs\n",
    "  X::Array{T, 1}                # Position\n",
    "  Gamma::Array{T, 1}            # Vectorial circulation\n",
    "  sigma::T                      # Smoothing radius\n",
    "\n",
    "  # Properties\n",
    "  U::Array{T, 1}                # Velocity at particle\n",
    "  J::Array{T, 2}                # Jacobian at particle J[i,j]=dUi/dxj\n",
    "\n",
    "end\n",
    "\n",
    "# Another initializer alias\n",
    "Particle{T}(X, Gamma, sigma) where {T} = Particle(X, Gamma, sigma, zeros(T,3), zeros(T, 3, 3))\n",
    "\n",
    "# Empty initializer\n",
    "Base.zero(::Type{<:Particle{T}}) where {T} = Particle(zeros(T, 3), zeros(T, 3),\n",
    "                                                      zero(T),\n",
    "                                                      zeros(T, 3), zeros(T, 3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "No modifications are needed in our `P2P_pythonic` function since Julia's multiple dispatch and JIT automatically compiles a version of the function specialized (optimized) for our new `Particle{T}` type on the fly. Still, we will define an alias to help us compare benchmarks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P2P_concretetypes (generic function with 1 method)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2P_concretetypes(args...) = P2P_pythonic(args...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2P_concretetypes    is  3.05 times faster than         P2P_pythonic (65.959ms vs 201.173ms)\n",
      "\n",
      "BenchmarkTools.Trial: \n",
      "  memory estimate:  189.93 MiB\n",
      "  allocs estimate:  2275776\n",
      "  --------------\n",
      "  minimum time:     65.959 ms (14.32% GC)\n",
      "  median time:      70.416 ms (16.18% GC)\n",
      "  mean time:        73.906 ms (19.34% GC)\n",
      "  maximum time:     116.967 ms (45.79% GC)\n",
      "  --------------\n",
      "  samples:          14\n",
      "  evals/sample:     1\n"
     ]
    }
   ],
   "source": [
    "# Create a 6x6x6 box of concrete Float64 particles\n",
    "particles = generate_particles(Particle{Float64}, n, lambda)\n",
    "\n",
    "args = (particles, g_wnk, dgdr_wnk)\n",
    "compare(P2P_concretetypes, P2P_pythonic, args)\n",
    "\n",
    "@benchmark P2P_concretetypes(args...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Voilà! By specifying concrete types in our `Particle` struct now we have gained a 3x speed up (we should `@code_warntype` again to make sure we got rid of all abstract types, but I'll omit it for brevity). \n",
    "\n",
    "Let's new see how we compare to C++:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C++                  is  4.95 times faster than    P2P_concretetypes (13.324ms vs 65.959ms)\n"
     ]
    }
   ],
   "source": [
    "printcomparison(P2P_concretetypes, \"C++\", false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Working with concrete types greatly sped up the computation; however, the C++ version is still ~5x faster than Julia. Let's see what else can we optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fix #2: Avoid List Comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The wonders of list comprehension may tempt you to do some line-efficient calculations; however, these will generally lead to a very inefficient computation. Take for example this list-comprehension sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  79.078 ns (1 allocation: 896 bytes)\n"
     ]
    }
   ],
   "source": [
    "sum_list(n) = sum([i for i in 1:n])\n",
    "\n",
    "@btime sum_list(100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here is the version of the same function unrolled without the list comprehension, which gains a ~60x speed up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.304 ns (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "function sum_unrolled(n)\n",
    "    out = 0\n",
    "    for i in 1:n\n",
    "        out += i\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "@btime sum_unrolled(100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In our P2P function we have a Kronecker delta cross product that we were calculating in just one line as\n",
    "\n",
    "```julia\n",
    "    # ∂u∂xj(x) = ∑[ ∂gσ∂xj(x−xp) * K(x−xp)×Γp + gσ(x−xp) * ∂K∂xj(x−xp)×Γp ]\n",
    "    for j in 1:3\n",
    "        Pi.J[:, j] += ( dX[j] / (Pj.sigma*r) * (dgsgmdr*crss) -\n",
    "                          gsgm * (3*dX[j]/r^2) * crss -\n",
    "                          gsgm * (const4/r^3) * cross([i==j for i in 1:3], Pj.Gamma) )\n",
    "    end\n",
    "```\n",
    "\n",
    "The alternative is to expand it into a few lines as\n",
    "\n",
    "```julia\n",
    "\n",
    "    # ∂u∂xj(x) = ∑[ ∂gσ∂xj(x−xp) * K(x−xp)×Γp + gσ(x−xp) * ∂K∂xj(x−xp)×Γp ]\n",
    "    for j in 1:3\n",
    "        Pi.J[:, j] += ( dX[j] / (Pj.sigma*r) * (dgsgmdr*crss) -\n",
    "                          gsgm * (3*dX[j]/r^2) * crss )\n",
    "    end\n",
    "    \n",
    "    # ∂u∂xj(x) = −∑gσ/(4πr^3) δij×Γp\n",
    "    # Adds the Kronecker delta term\n",
    "    aux = -const4 * gsgm / r^3\n",
    "    # j=1\n",
    "    Pi.J[2, 1] -= aux * Pj.Gamma[3]\n",
    "    Pi.J[3, 1] += aux * Pj.Gamma[2]\n",
    "    # j=2\n",
    "    Pi.J[1, 2] += aux * Pj.Gamma[3]\n",
    "    Pi.J[3, 2] -= aux * Pj.Gamma[1]\n",
    "    # j=3\n",
    "    Pi.J[1, 3] -= aux * Pj.Gamma[2]\n",
    "    Pi.J[2, 3] += aux * Pj.Gamma[1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The problem with list comprehension operations is that it has to allocate memory to build the array prior to operating. Just resist the temptation of using list comprehension to save yourself a few lines, and simply unroll it. As seen below we get a 1.5x speed up by unrolling this line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P2P_nocomprehension"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Unrolling the list comprehension\n",
    "\"\"\"\n",
    "function P2P_nocomprehension(particles, g, dgdr)\n",
    "\n",
    "    for Pi in particles \n",
    "        for Pj in particles    \n",
    "\n",
    "            dX = Pi.X - Pj.X\n",
    "            r = norm(dX)\n",
    "\n",
    "            if r != 0\n",
    "\n",
    "                # g_σ and ∂gσ∂r\n",
    "                gsgm = g(r / Pj.sigma)\n",
    "                dgsgmdr = dgdr(r / Pj.sigma)\n",
    "\n",
    "                # K × Γp\n",
    "                crss = cross(-const4 * (dX/r^3), Pj.Gamma) \n",
    "\n",
    "                # U = ∑g_σ(x-xp) * K(x-xp) × Γp\n",
    "                Pi.U[:] += gsgm * crss\n",
    "\n",
    "                # ∂u∂xj(x) = ∑[ ∂gσ∂xj(x−xp) * K(x−xp)×Γp + gσ(x−xp) * ∂K∂xj(x−xp)×Γp ]\n",
    "                for j in 1:3\n",
    "                    Pi.J[:, j] += ( dX[j] / (Pj.sigma*r) * (dgsgmdr*crss) -\n",
    "                                      gsgm * (3*dX[j]/r^2) * crss )\n",
    "                end\n",
    "                \n",
    "                # ∂u∂xj(x) = −∑gσ/(4πr^3) δij×Γp\n",
    "                # Adds the Kronecker delta term\n",
    "                aux = -const4 * gsgm / r^3\n",
    "                # j=1\n",
    "                Pi.J[2, 1] -= aux * Pj.Gamma[3]\n",
    "                Pi.J[3, 1] += aux * Pj.Gamma[2]\n",
    "                # j=2\n",
    "                Pi.J[1, 2] += aux * Pj.Gamma[3]\n",
    "                Pi.J[3, 2] -= aux * Pj.Gamma[1]\n",
    "                # j=3\n",
    "                Pi.J[1, 3] -= aux * Pj.Gamma[2]\n",
    "                Pi.J[2, 3] += aux * Pj.Gamma[1]\n",
    "                \n",
    "            end\n",
    "\n",
    "        end\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2P_nocomprehension  is  1.43 times faster than    P2P_concretetypes (46.066ms vs 65.959ms)\n",
      "\n",
      "BenchmarkTools.Trial: \n",
      "  memory estimate:  126.16 MiB\n",
      "  allocs estimate:  1300536\n",
      "  --------------\n",
      "  minimum time:     46.066 ms (13.82% GC)\n",
      "  median time:      51.316 ms (16.30% GC)\n",
      "  mean time:        55.791 ms (19.74% GC)\n",
      "  maximum time:     99.415 ms (50.81% GC)\n",
      "  --------------\n",
      "  samples:          18\n",
      "  evals/sample:     1\n"
     ]
    }
   ],
   "source": [
    "args = (particles, g_wnk, dgdr_wnk)\n",
    "compare(P2P_nocomprehension, P2P_concretetypes, args)\n",
    "\n",
    "@benchmark P2P_nocomprehension(args...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fix #3: Reduce Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next, we notice that the benchmarking test is allotting an unusual amount of memory (126MiB) and allocation operations (1.3M). I am suspicious that this is an issue with Julia allowing arrays of dynamic sizes. The first step to solve this is to **do away with creating any internal variables of type arrays**. In the code bellow, notice that I had replaced the array variables `dX` and `crss` with float variables `dX1, dX2, dX3`, and `crss1, crss2, crss3`, which leads to having to fully unroll the inner for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P2P_noallocation"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Reducing memory allocation\n",
    "\"\"\"\n",
    "function P2P_noallocation(particles, g, dgdr)\n",
    "\n",
    "    for Pi in particles \n",
    "        for Pj in particles    \n",
    "\n",
    "            dX1 = Pi.X[1] - Pj.X[1]\n",
    "            dX2 = Pi.X[2] - Pj.X[2]\n",
    "            dX3 = Pi.X[3] - Pj.X[3]\n",
    "            r = norm(Pi.X - Pj.X)\n",
    "\n",
    "            if r != 0\n",
    "\n",
    "                # g_σ and ∂gσ∂r\n",
    "                gsgm = g(r / Pj.sigma)\n",
    "                dgsgmdr = dgdr(r / Pj.sigma)\n",
    "\n",
    "                # K × Γp\n",
    "                crss1, crss2, crss3 = -const4 / r^3 * cross(Pi.X - Pj.X, Pj.Gamma)\n",
    "\n",
    "                # U = ∑g_σ(x-xp) * K(x-xp) × Γp\n",
    "                Pi.U[1] += gsgm * crss1\n",
    "                Pi.U[2] += gsgm * crss2\n",
    "                Pi.U[3] += gsgm * crss3\n",
    "\n",
    "                # ∂u∂xj(x) = ∑[ ∂gσ∂xj(x−xp) * K(x−xp)×Γp + gσ(x−xp) * ∂K∂xj(x−xp)×Γp ]\n",
    "                # ∂u∂xj(x) = ∑p[(Δxj∂gσ∂r/(σr) − 3Δxjgσ/r^2) K(Δx)×Γp\n",
    "                aux = dgsgmdr/(Pj.sigma*r)* - 3*gsgm /r^2\n",
    "                # j=1\n",
    "                Pi.J[1, 1] += aux * crss1 * dX1\n",
    "                Pi.J[2, 1] += aux * crss2 * dX1\n",
    "                Pi.J[3, 1] += aux * crss3 * dX1\n",
    "                # j=2\n",
    "                Pi.J[1, 2] += aux * crss1 * dX2\n",
    "                Pi.J[2, 2] += aux * crss2 * dX2\n",
    "                Pi.J[3, 2] += aux * crss3 * dX2\n",
    "                # j=3\n",
    "                Pi.J[1, 3] += aux * crss1 * dX3\n",
    "                Pi.J[2, 3] += aux * crss2 * dX3\n",
    "                Pi.J[3, 3] += aux * crss3 * dX3\n",
    "                \n",
    "                # Adds the Kronecker delta term\n",
    "                aux = -const4 * gsgm / r^3\n",
    "                # j=1\n",
    "                Pi.J[2, 1] -= aux * Pj.Gamma[3]\n",
    "                Pi.J[3, 1] += aux * Pj.Gamma[2]\n",
    "                # j=2\n",
    "                Pi.J[1, 2] += aux * Pj.Gamma[3]\n",
    "                Pi.J[3, 2] -= aux * Pj.Gamma[1]\n",
    "                # j=3\n",
    "                Pi.J[1, 3] -= aux * Pj.Gamma[2]\n",
    "                Pi.J[2, 3] += aux * Pj.Gamma[1]\n",
    "                \n",
    "            end\n",
    "\n",
    "        end\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2P_noallocation     is  3.49 times faster than  P2P_nocomprehension (13.190ms vs 46.066ms)\n",
      "\n",
      "BenchmarkTools.Trial: \n",
      "  memory estimate:  21.99 MiB\n",
      "  allocs estimate:  325296\n",
      "  --------------\n",
      "  minimum time:     13.190 ms (9.72% GC)\n",
      "  median time:      13.582 ms (10.01% GC)\n",
      "  mean time:        15.246 ms (14.50% GC)\n",
      "  maximum time:     51.843 ms (70.12% GC)\n",
      "  --------------\n",
      "  samples:          66\n",
      "  evals/sample:     1\n"
     ]
    }
   ],
   "source": [
    "args = (particles, g_wnk, dgdr_wnk)\n",
    "compare(P2P_noallocation, P2P_nocomprehension, args)\n",
    "\n",
    "@benchmark P2P_noallocation(args...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we have reduced the memory allocated from 126MiB to 22MiB, leading to a 3.5x speed up. Let's see what else can we do to decrease that that memory allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fix #4: No Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The next thing to consider is that trying to do any **linear algebra operation (dot product, cross product, even norm) in a functional form (i.e., `dot(X,X)`, `cross(X,X)`, `norm(X,X)`) is more expensive that explicitely unfolding the operation into lines of code**. I am suspicious that this is a memory allocation problem since these functions need to allocate internal array variables to store computation and output the result. Here is the code without any functional linear algebra operations (notice that I no longer use `norm` nor `cross`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P2P_nolinalg"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    No linear algebra functions\n",
    "\"\"\"\n",
    "function P2P_nolinalg(particles, g, dgdr)\n",
    "\n",
    "    for Pi in particles \n",
    "        for Pj in particles    \n",
    "\n",
    "            dX1 = Pi.X[1] - Pj.X[1]\n",
    "            dX2 = Pi.X[2] - Pj.X[2]\n",
    "            dX3 = Pi.X[3] - Pj.X[3]\n",
    "            r = sqrt(dX1*dX1 + dX2*dX2 + dX3*dX3)\n",
    "\n",
    "            if r != 0\n",
    "\n",
    "                # g_σ and ∂gσ∂r\n",
    "                gsgm = g(r / Pj.sigma)\n",
    "                dgsgmdr = dgdr(r / Pj.sigma)\n",
    "\n",
    "                # K × Γp\n",
    "                crss1 = -const4 / r^3 * ( dX2*Pj.Gamma[3] - dX3*Pj.Gamma[2] )\n",
    "                crss2 = -const4 / r^3 * ( dX3*Pj.Gamma[1] - dX1*Pj.Gamma[3] )\n",
    "                crss3 = -const4 / r^3 * ( dX1*Pj.Gamma[2] - dX2*Pj.Gamma[1] )\n",
    "\n",
    "                # U = ∑g_σ(x-xp) * K(x-xp) × Γp\n",
    "                Pi.U[1] += gsgm * crss1\n",
    "                Pi.U[2] += gsgm * crss2\n",
    "                Pi.U[3] += gsgm * crss3\n",
    "\n",
    "                # ∂u∂xj(x) = ∑[ ∂gσ∂xj(x−xp) * K(x−xp)×Γp + gσ(x−xp) * ∂K∂xj(x−xp)×Γp ]\n",
    "                # ∂u∂xj(x) = ∑p[(Δxj∂gσ∂r/(σr) − 3Δxjgσ/r^2) K(Δx)×Γp\n",
    "                aux = dgsgmdr/(Pj.sigma*r)* - 3*gsgm /r^2\n",
    "                # j=1\n",
    "                Pi.J[1, 1] += aux * crss1 * dX1\n",
    "                Pi.J[2, 1] += aux * crss2 * dX1\n",
    "                Pi.J[3, 1] += aux * crss3 * dX1\n",
    "                # j=2\n",
    "                Pi.J[1, 2] += aux * crss1 * dX2\n",
    "                Pi.J[2, 2] += aux * crss2 * dX2\n",
    "                Pi.J[3, 2] += aux * crss3 * dX2\n",
    "                # j=3\n",
    "                Pi.J[1, 3] += aux * crss1 * dX3\n",
    "                Pi.J[2, 3] += aux * crss2 * dX3\n",
    "                Pi.J[3, 3] += aux * crss3 * dX3\n",
    "                \n",
    "                # Adds the Kronecker delta term\n",
    "                aux = -const4 * gsgm / r^3\n",
    "                # j=1\n",
    "                Pi.J[2, 1] -= aux * Pj.Gamma[3]\n",
    "                Pi.J[3, 1] += aux * Pj.Gamma[2]\n",
    "                # j=2\n",
    "                Pi.J[1, 2] += aux * Pj.Gamma[3]\n",
    "                Pi.J[3, 2] -= aux * Pj.Gamma[1]\n",
    "                # j=3\n",
    "                Pi.J[1, 3] -= aux * Pj.Gamma[2]\n",
    "                Pi.J[2, 3] += aux * Pj.Gamma[1]\n",
    "                \n",
    "            end\n",
    "\n",
    "        end\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2P_nolinalg         is  2.08 times faster than     P2P_noallocation (6.327ms vs 13.190ms)\n",
      "\n",
      "BenchmarkTools.Trial: \n",
      "  memory estimate:  0 bytes\n",
      "  allocs estimate:  0\n",
      "  --------------\n",
      "  minimum time:     6.327 ms (0.00% GC)\n",
      "  median time:      6.424 ms (0.00% GC)\n",
      "  mean time:        6.497 ms (0.00% GC)\n",
      "  maximum time:     7.497 ms (0.00% GC)\n",
      "  --------------\n",
      "  samples:          154\n",
      "  evals/sample:     1\n"
     ]
    }
   ],
   "source": [
    "args = (particles, g_wnk, dgdr_wnk)\n",
    "compare(P2P_nolinalg, P2P_noallocation, args)\n",
    "\n",
    "@benchmark P2P_nolinalg(args...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "By doing away with linear algebra functions we are now **not allocating any memory, reaching an extra 2x speed up**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fix #5: Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C++                  is  0.47 times faster than         P2P_nolinalg (13.324ms vs 6.327ms)\n"
     ]
    }
   ],
   "source": [
    "printcomparison(P2P_nolinalg, \"C++\", false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Notice that by now we are achieving benchmarks in the same order of magnitude than C++ (2.09ms in Julia vs 0.59ms in C++). What we did prior to this point were general principles that apply to any code that attempts to get high performance. What it follows now is fine tune our code in ways that only apply to the specific computation that we are performing.\n",
    "\n",
    "For instance, recall that our P2P function receives any user-defined regularizing kernel that our function calls through this lines:\n",
    "\n",
    "```julia\n",
    "function P2P(sources, targets, g::Function, dgdr::Function)\n",
    "\n",
    "    for Pi in targets\n",
    "        for Pj in sources\n",
    "            .\n",
    "            .\n",
    "            .\n",
    "            # g_σ and ∂gσ∂r\n",
    "            gsgm = g(r / Pj.sigma)\n",
    "            dgsgmdr = dgdr(r / Pj.sigma)\n",
    "            .\n",
    "            .\n",
    "            .\n",
    "        end\n",
    "    end\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the case of Winckelmans' kernel, `g` and `dgdr` look like this:\n",
    "```julia\n",
    "g_wnk(r) = r^3 * (r^2 + 2.5) / (r^2 + 1)^2.5\n",
    "dgdr_wnk(r) = 7.5 * r^2 / (r^2 + 1)^3.5\n",
    "```\n",
    "\n",
    "We notice that each of these function calculate a power operation independently, `(r^2 + 1)^2.5` and `(r^2 + 1)^3.5`. I have observed that **any sort of non-integer power operation takes Julia more than than basic arithmetic operations or even space allocation**. We can save computation by merging this two functions and reusing the square root calculation as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P2P_reusesqrt"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function g_dgdr_wnk(r)\n",
    "    aux = (r^2 + 1)^2.5\n",
    "\n",
    "    # Returns g and dgdr\n",
    "    return r^3*(r^2 + 2.5)/aux, 7.5*r^2/(aux*(r^2 + 1))\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    Reuses sqrt, reducing to only one calculation\n",
    "\"\"\"\n",
    "function P2P_reusesqrt(particles, g_dgdr)\n",
    "\n",
    "    for Pi in particles \n",
    "        for Pj in particles    \n",
    "\n",
    "            dX1 = Pi.X[1] - Pj.X[1]\n",
    "            dX2 = Pi.X[2] - Pj.X[2]\n",
    "            dX3 = Pi.X[3] - Pj.X[3]\n",
    "            r = sqrt(dX1*dX1 + dX2*dX2 + dX3*dX3)\n",
    "\n",
    "            if r != 0\n",
    "\n",
    "                # g_σ and ∂gσ∂r\n",
    "                gsgm, dgsgmdr = g_dgdr(r / Pj.sigma)\n",
    "\n",
    "                # K × Γp\n",
    "                crss1 = -const4 / r^3 * ( dX2*Pj.Gamma[3] - dX3*Pj.Gamma[2] )\n",
    "                crss2 = -const4 / r^3 * ( dX3*Pj.Gamma[1] - dX1*Pj.Gamma[3] )\n",
    "                crss3 = -const4 / r^3 * ( dX1*Pj.Gamma[2] - dX2*Pj.Gamma[1] )\n",
    "\n",
    "                # U = ∑g_σ(x-xp) * K(x-xp) × Γp\n",
    "                Pi.U[1] += gsgm * crss1\n",
    "                Pi.U[2] += gsgm * crss2\n",
    "                Pi.U[3] += gsgm * crss3\n",
    "\n",
    "                # ∂u∂xj(x) = ∑[ ∂gσ∂xj(x−xp) * K(x−xp)×Γp + gσ(x−xp) * ∂K∂xj(x−xp)×Γp ]\n",
    "                # ∂u∂xj(x) = ∑p[(Δxj∂gσ∂r/(σr) − 3Δxjgσ/r^2) K(Δx)×Γp\n",
    "                aux = dgsgmdr/(Pj.sigma*r)* - 3*gsgm /r^2\n",
    "                # j=1\n",
    "                Pi.J[1, 1] += aux * crss1 * dX1\n",
    "                Pi.J[2, 1] += aux * crss2 * dX1\n",
    "                Pi.J[3, 1] += aux * crss3 * dX1\n",
    "                # j=2\n",
    "                Pi.J[1, 2] += aux * crss1 * dX2\n",
    "                Pi.J[2, 2] += aux * crss2 * dX2\n",
    "                Pi.J[3, 2] += aux * crss3 * dX2\n",
    "                # j=3\n",
    "                Pi.J[1, 3] += aux * crss1 * dX3\n",
    "                Pi.J[2, 3] += aux * crss2 * dX3\n",
    "                Pi.J[3, 3] += aux * crss3 * dX3\n",
    "                \n",
    "                # Adds the Kronecker delta term\n",
    "                aux = -const4 * gsgm / r^3\n",
    "                # j=1\n",
    "                Pi.J[2, 1] -= aux * Pj.Gamma[3]\n",
    "                Pi.J[3, 1] += aux * Pj.Gamma[2]\n",
    "                # j=2\n",
    "                Pi.J[1, 2] += aux * Pj.Gamma[3]\n",
    "                Pi.J[3, 2] -= aux * Pj.Gamma[1]\n",
    "                # j=3\n",
    "                Pi.J[1, 3] -= aux * Pj.Gamma[2]\n",
    "                Pi.J[2, 3] += aux * Pj.Gamma[1]\n",
    "                \n",
    "            end\n",
    "\n",
    "        end\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2P_reusesqrt        is  1.53 times faster than         P2P_nolinalg (4.128ms vs 6.327ms)\n",
      "\n",
      "BenchmarkTools.Trial: \n",
      "  memory estimate:  0 bytes\n",
      "  allocs estimate:  0\n",
      "  --------------\n",
      "  minimum time:     4.128 ms (0.00% GC)\n",
      "  median time:      5.027 ms (0.00% GC)\n",
      "  mean time:        5.055 ms (0.00% GC)\n",
      "  maximum time:     7.390 ms (0.00% GC)\n",
      "  --------------\n",
      "  samples:          198\n",
      "  evals/sample:     1\n"
     ]
    }
   ],
   "source": [
    "args = (particles, g_dgdr_wnk)\n",
    "compare(P2P_reusesqrt, P2P_nolinalg, args)\n",
    "\n",
    "@benchmark P2P_reusesqrt(args...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Hence, by **simply avoiding one extra power calculation we have now gained a 1.5x speed up.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix #6: Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is straight from the Julia official documentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`@inbounds`](https://docs.julialang.org/en/v1/devdocs/boundscheck/index.html)\n",
    ">Like many modern programming languages, Julia uses bounds checking to ensure program safety when accessing arrays. In tight inner loops or other performance critical situations, you may wish to skip these bounds checks to improve runtime performance. For instance, in order to emit vectorized (SIMD) instructions, your loop body cannot contain branches, and thus cannot contain bounds checks. Consequently, Julia includes an @inbounds(...) macro to tell the compiler to skip such bounds checks within the given block. User-defined array types can use the @boundscheck(...) macro to achieve context-sensitive code selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`@simd`](https://docs.julialang.org/en/v1/manual/performance-tips/index.html#man-performance-annotations-1)\n",
    "> Write @simd in front of for loops to promise that the iterations are independent and may be reordered. Note that in many cases, Julia can automatically vectorize code without the @simd macro; it is only beneficial in cases where such a transformation would otherwise be illegal, including cases like allowing floating-point re-associativity and ignoring dependent memory accesses (@simd ivdep). Again, be very careful when asserting @simd as erroneously annotating a loop with dependent iterations may result in unexpected results. In particular, note that setindex! on some AbstractArray subtypes is inherently dependent upon iteration order. This feature is experimental and could change or disappear in future versions of Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`@fastmath`](https://docs.julialang.org/en/v1/manual/performance-tips/index.html#man-performance-annotations-1)\n",
    "> Use @fastmath to allow floating point optimizations that are correct for real numbers, but lead to differences for IEEE numbers. Be careful when doing this, as this may change numerical results. This corresponds to the -ffast-math option of clang."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I won't dive into details, but what I have realized is that you can get a speed up from the three macros listed above only when you are working with [data structures that pass the `isbits` test](https://docs.julialang.org/en/v1/devdocs/isbitsunionarrays/). In practice, that means that our structs can't contain any arrays, which lead us to redefining the struct as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct ParticleNoArr{T}\n",
    "\n",
    "  # User inputs\n",
    "  X1::T\n",
    "  X2::T\n",
    "  X3::T\n",
    "  Gamma1::T\n",
    "  Gamma2::T\n",
    "  Gamma3::T\n",
    "  sigma::T\n",
    "\n",
    "end\n",
    "\n",
    "# Empty initializer\n",
    "Base.zero(::Type{<:ParticleNoArr{T}}) where {T} = ParticleNoArr(zeros(T, 7)...)\n",
    "\n",
    "# Another initializer alias\n",
    "ParticleNoArr{T}(X, Gamma, sigma) where T = ParticleNoArr(X..., Gamma..., sigma);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that twist, now we implement `@simd` in the internal for loop, and both `@fastmath` and `@inbounds` wrapping all floating point operations and output allocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P2P_misc"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Implementation of @simd, @fastmath, and @inbounds\n",
    "\"\"\"\n",
    "function P2P_misc(particles, g_dgdr, U, J)\n",
    "\n",
    "    for (i, Pi) in enumerate(particles)\n",
    "        @simd for Pj in particles\n",
    "\n",
    "            @fastmath @inbounds begin\n",
    "                dX1 = Pi.X1 - Pj.X1\n",
    "                dX2 = Pi.X2 - Pj.X2\n",
    "                dX3 = Pi.X3 - Pj.X3\n",
    "                r = sqrt(dX1*dX1 + dX2*dX2 + dX3*dX3)\n",
    "\n",
    "                if r != 0\n",
    "\n",
    "                    # g_σ and ∂gσ∂r\n",
    "                    gsgm, dgsgmdr = g_dgdr(r / Pj.sigma)\n",
    "\n",
    "                    # K × Γp\n",
    "                    crss1 = -const4 / r^3 * ( dX2*Pj.Gamma3 - dX3*Pj.Gamma2 )\n",
    "                    crss2 = -const4 / r^3 * ( dX3*Pj.Gamma1 - dX1*Pj.Gamma3 )\n",
    "                    crss3 = -const4 / r^3 * ( dX1*Pj.Gamma2 - dX2*Pj.Gamma1 )\n",
    "\n",
    "                    # U = ∑g_σ(x-xp) * K(x-xp) × Γp\n",
    "                    U[1, i] += gsgm * crss1\n",
    "                    U[2, i] += gsgm * crss2\n",
    "                    U[3, i] += gsgm * crss3\n",
    "\n",
    "                    # ∂u∂xj(x) = ∑[ ∂gσ∂xj(x−xp) * K(x−xp)×Γp + gσ(x−xp) * ∂K∂xj(x−xp)×Γp ]\n",
    "                    # ∂u∂xj(x) = ∑p[(Δxj∂gσ∂r/(σr) − 3Δxjgσ/r^2) K(Δx)×Γp\n",
    "                    aux = dgsgmdr/(Pj.sigma*r)* - 3*gsgm /r^2\n",
    "                    # j=1\n",
    "                    J[1, 1, i] += aux * crss1 * dX1\n",
    "                    J[2, 1, i] += aux * crss2 * dX1\n",
    "                    J[3, 1, i] += aux * crss3 * dX1\n",
    "                    # j=2\n",
    "                    J[1, 2, i] += aux * crss1 * dX2\n",
    "                    J[2, 2, i] += aux * crss2 * dX2\n",
    "                    J[3, 2, i] += aux * crss3 * dX2\n",
    "                    # j=3\n",
    "                    J[1, 3, i] += aux * crss1 * dX3\n",
    "                    J[2, 3, i] += aux * crss2 * dX3\n",
    "                    J[3, 3, i] += aux * crss3 * dX3\n",
    "\n",
    "                    # Adds the Kronecker delta term\n",
    "                    aux = -const4 * gsgm / r^3\n",
    "                    # j=1\n",
    "                    J[2, 1, i] -= aux * Pj.Gamma3\n",
    "                    J[3, 1, i] += aux * Pj.Gamma2\n",
    "                    # j=2\n",
    "                    J[1, 2, i] += aux * Pj.Gamma3\n",
    "                    J[3, 2, i] -= aux * Pj.Gamma1\n",
    "                    # j=3\n",
    "                    J[1, 3, i] -= aux * Pj.Gamma2\n",
    "                    J[2, 3, i] += aux * Pj.Gamma1\n",
    "\n",
    "                end\n",
    "            end\n",
    "\n",
    "        end\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2P_misc             is  1.18 times faster than        P2P_reusesqrt (3.485ms vs 4.128ms)\n",
      "\n",
      "BenchmarkTools.Trial: \n",
      "  memory estimate:  0 bytes\n",
      "  allocs estimate:  0\n",
      "  --------------\n",
      "  minimum time:     3.485 ms (0.00% GC)\n",
      "  median time:      3.543 ms (0.00% GC)\n",
      "  mean time:        3.588 ms (0.00% GC)\n",
      "  maximum time:     4.514 ms (0.00% GC)\n",
      "  --------------\n",
      "  samples:          279\n",
      "  evals/sample:     1\n"
     ]
    }
   ],
   "source": [
    "# Create a 6x6x6 box of particles of our new ParticleNoArr struct\n",
    "particlesNoArr = generate_particles(ParticleNoArr{Float64}, n, lambda)\n",
    "\n",
    "# Pre-allocate outputs in separate arrays\n",
    "U = zeros(Float64, 3, length(particlesNoArr) )\n",
    "J = zeros(Float64, 3, 3, length(particlesNoArr) )\n",
    "\n",
    "# Benchmark\n",
    "args = (particlesNoArr, g_dgdr_wnk, U, J)\n",
    "compare(P2P_misc, P2P_reusesqrt, args)\n",
    "\n",
    "@benchmark P2P_misc(args...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2P_misc             is  3.82 times faster than                  C++ (3.485ms vs 13.324ms)\n"
     ]
    }
   ],
   "source": [
    "printcomparison(P2P_misc, \"C++\", true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Winckelmans, G. S., & Leonard, A. (1993). Contributions to Vortex Particle Methods for the Computation of Three-Dimensional Incompressible Unsteady Flows. Journal of Computational Physics, 109(2), 247–273. https://doi.org/10.1006/jcph.1993.1216\n",
    "2. Alvarez, E. J., & Ning, A. (2018). Development of a Vortex Particle Code for the Modeling of Wake Interaction in Distributed Propulsion. In 2018 Applied Aerodynamics Conference (pp. 1–22). American Institute of Aeronautics and Astronautics. https://doi.org/10.2514/6.2018-3646 . [PDF Available](https://scholarsarchive.byu.edu/facpub/2116/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All benchmarks here detailed were done on my Dell Latitude 5580 laptop (Intel® Core™ i7-7820HQ CPU @ 2.90GHz × 8 ) in only one process.\n",
    "* Julia v1.0.3 was used.\n",
    "* The official [Julia documentation](https://docs.julialang.org/en/v1/manual/performance-tips/index.html) also provide very useful tips for performance.\n",
    "\n",
    "\n",
    "https://aaronang.github.io/2018/stl-benchmark-comparison-cpp-vs-julia/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict{Union{Function, String},Float64}(P2P_pythonic=>201.173,P2P_concretetypes=>65.9595,P2P_miscNoArr=>3.48742,P2P_reusesqrt=>4.12761,P2P_nolinalg=>6.32728,P2P_nocomprehension=>46.0656,\"C++\"=>13.3236,P2P_noallocation=>13.1897,P2P_misc=>3.48543)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Union{Function, String},Float64} with 9 entries:\n",
       "  P2P_pythonic        => 201.173\n",
       "  P2P_concretetypes   => 65.9595\n",
       "  P2P_miscNoArr       => 3.48742\n",
       "  P2P_reusesqrt       => 4.12761\n",
       "  P2P_nolinalg        => 6.32728\n",
       "  P2P_nocomprehension => 46.0656\n",
       "  \"C++\"               => 13.3236\n",
       "  P2P_noallocation    => 13.1897\n",
       "  P2P_misc            => 3.48543"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(benchtime)\n",
    "benchtime"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
